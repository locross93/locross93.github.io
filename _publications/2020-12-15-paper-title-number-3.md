---
title: "Using deep reinforcement learning to reveal how the brain encodes abstract state-space representations in high-dimensional environments"
collection: publications
permalink: /publication/2020-12-15-paper-title-number-3
excerpt: ''
date: 2021-02-17
venue: 'Neuron'
paperurl: 'https://www.cell.com/neuron/fulltext/S0896-6273(20)30899-0'
citation: 'Cross, L., Cockburn, J., Yue, Yisong, & Oâ€™Doherty, J.P. (2021). Using deep reinforcement learning to reveal how the brain encodes abstract state-space representations in high-dimensional environments. Neuron, 109(4), 724-738. https://doi.org/10.1016/j.neuron.2020.11.021.'
---
Abstract
=====
Humans possess an exceptional aptitude to efficiently make decisions from high-dimensional sensory observations. However, it is unknown how the brain compactly represents the current state of the environment to guide this process. The deep Q-network (DQN) achieves this by capturing highly nonlinear mappings from multivariate inputs to the values of potential actions. We deployed DQN as a model of brain activity and behavior in participants playing three Atari video games during fMRI. Hidden layers of DQN exhibited a striking resemblance to voxel activity in a distributed sensorimotor network, extending throughout the dorsal visual pathway into posterior parietal cortex. Neural state-space representations emerged from nonlinear transformations of the pixel space bridging perception to action and reward. These transformations reshape axes to reflect relevant high-level features and strip away information about task-irrelevant sensory features. Our findings shed light on the neural encoding of task representations for decision-making in real-world situations.

[Access paper here](https://www.cell.com/neuron/fulltext/S0896-6273(20)30899-0)
